import os

from argparse import ArgumentParser

def get_args():
    parser = ArgumentParser(description='SED-Stock related Event Detection.')
    parser.add_argument('input', type=str, default="../ni_data/word201505/", help="input file dir path")
    parser.add_argument('--dev', action='store_true', dest='dev', help='get the development set result')
    parser.add_argument('--test', action='store_true', dest='test', help='get the test set result')
    parser.add_argument('--output', type=str, default='v', help='output development or test result')

    parser.add_argument('--use_df', action='store_true', help='whether to calculate df or load available df')
    parser.add_argument('--use_zs', action='store_true', help='whether to calculate zscore or load available')
    parser.add_argument('--do_cls', action='store_true', help='whether to cluster or load available')
    parser.add_argument('--df_file', type=str, default='.df', help="filepath of df values")
    parser.add_argument('--zs_file', type=str, default='.zs', help="filepath of zs values")
    parser.add_argument('--cls_file', type=str, default='.cluster', help="filepath of cluter results")
    parser.add_argument('--evt_file', type=str, default='.event', help="filepath of event results")

    # previous testvec
    parser.add_argument('--vec', type=int, default=3, action='append', help="how to get tweet vector. default: avg of word embeds")

    parser.add_argument('--ltw', type=int, default=10, help="left window size used in zscore")
    parser.add_argument('--rtw', type=int, default=0, help="right window size used in zscore")

    parser.add_argument('--tf', action='store_true', help="whether to use bursty tweet filtering")
    parser.add_argument('--rdist', type=float, default=0.4, help="threshold of radius distance for df calculation")
    parser.add_argument('--delta', type=float, default=5.0, help="threshold of zs to filter tweets")
    parser.add_argument('--lsh_probes', type=int, default=20, help="number of probes in LSH")

    parser.add_argument('--cluster', type=str, default="dbscan", help="clustering algorithm. kmeans, affi, spec, agg, dbscan")
    parser.add_argument('--dbscan_eps', type=float, default=0.2, help="threshold of dbscan eps")
    parser.add_argument('--num_cls', type=int, default=-1, help="number of clusters. default -1")
    parser.add_argument('--kc', type=int, default=30, help="top kc clusters selected as results")
    parser.add_argument('--kt', type=int, default=5, help="top kt tweets in a cluster are selected as results")
    parser.add_argument('--kc_step', type=int, default=5, help="output eval metrics in topK results. default: top5, top10, top15, until top_Kc")
    parser.add_argument('--news_window', type=int, default=0, help="do we consider news in current+[-1, 0, 1] for evaluation or just [0]")

    parser.add_argument('--snp_file', type=str, default='../data/snp500_sutd')
    parser.add_argument('--word_vectors', type=str, default='../ni_data/tweetVec/w2v1010100-en')
    parser.add_argument('--news_vectors', type=str, default='../ni_data/tweetVec/stockNewsVec1_Loose1', help="stock news' vector, used for evaluate recall of twitter events")
    parser.add_argument('--tfidf_dict', type=str, default='../ni_data/word201505/tweets_tfidf.dict', help="tfidf_dict, generated by nltk, used for tfidf representation")
    parser.add_argument('--tfidf_corpus', type=str, default='../ni_data/word201505/tweets_tfidf.mm', help="tfidf_corpus, generated by nltk, used for tfidf representation")
    args = parser.parse_args()
    return args
